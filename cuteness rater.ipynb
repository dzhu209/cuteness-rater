{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9912 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Id  Pawpularity\n",
       "0     0007de18844b0dbbb5e1f607da0606e0           63\n",
       "1     0009c66b9439883ba2750fb825e1d7db           42\n",
       "2     0013fd999caf9a3efe1352ca1b0d937e           28\n",
       "3     0018df346ac9c1d8413cfcc888ca8246           15\n",
       "4     001dc955e10590d3ca4673f034feeef2           72\n",
       "...                                ...          ...\n",
       "9907  ffbfa0383c34dc513c95560d6e1fdb57           15\n",
       "9908  ffcc8532d76436fc79e50eb2e5238e45           70\n",
       "9909  ffdf2e8673a1da6fb80342fa3b119a20           20\n",
       "9910  fff19e2ce11718548fa1c5d039a5192a           20\n",
       "9911  fff8e47c766799c9e12f3cb3d66ad228           30\n",
       "\n",
       "[9912 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"labels.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat Pawpularity as a continuous variable in the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of the \"Pawpularity\" column\n",
    "plt.hist(df['Pawpularity'], bins=30, edgecolor='black')\n",
    "plt.xlabel('Pawpularity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Pawpularity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image directory\n",
    "image_dir = \"images\"\n",
    "\n",
    "# Initialize lists to store images and pawpularity values\n",
    "images = []\n",
    "pawpularity = []\n",
    "\n",
    "# Define the desired image size\n",
    "image_size = (64, 64)\n",
    "\n",
    "# Iterate over the IDs in the DataFrame\n",
    "for id in df[\"Id\"]:\n",
    "    # Construct the image filename by appending the \".jpg\" extension\n",
    "    filename = id + \".jpg\"\n",
    "\n",
    "    # Construct the path to the image file\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = load_img(image_path, target_size=image_size)\n",
    "    image = img_to_array(image) / 255.0\n",
    "\n",
    "    # Add the preprocessed image to the images list\n",
    "    images.append(image)\n",
    "\n",
    "    # Extract the corresponding pawpularity value from the DataFrame\n",
    "    pawpularity_value = df.loc[df[\"Id\"] == id, \"Pawpularity\"].values[0]\n",
    "    pawpularity.append(pawpularity_value)\n",
    "\n",
    "# Convert the images and pawpularity lists to NumPy arrays\n",
    "images = np.array(images)\n",
    "pawpularity = np.array(pawpularity)\n",
    "\n",
    "# Reshape the pawpularity array to match the shape of the images array\n",
    "pawpularity = pawpularity.reshape(-1, 1)\n",
    "\n",
    "# Normalize the pawpularity values using Min-Max scaling\n",
    "# scaler = MinMaxScaler()\n",
    "# pawpularity = scaler.fit_transform(pawpularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7929, 64, 64, 3)\n",
      "y_train shape: (7929, 1)\n",
      "x_test shape: (1983, 64, 64, 3)\n",
      "y_test shape: (1983, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, pawpularity, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of x_train, x_test, y_train, and y_test\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "248/248 [==============================] - 8s 32ms/step - loss: 0.0909\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 8s 33ms/step - loss: 0.0438\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 8s 32ms/step - loss: 0.0423\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 8s 32ms/step - loss: 0.0395\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 0.0350\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 9s 35ms/step - loss: 0.0316\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.0292\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 9s 38ms/step - loss: 0.0249\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 9s 36ms/step - loss: 0.0228\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 0.0194\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 0.0683\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.0438\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.0418\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.0380\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 50ms/step - loss: 0.0338\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 11s 44ms/step - loss: 0.0296\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0255\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.0229\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 0.0201\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.0177\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 0.0600\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0434\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.0425\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 0.0392\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0355\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 0.0319\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0284\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.0251\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 50ms/step - loss: 0.0231\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 0.0201\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.0503\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.0439\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 0.0433\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 0.0410\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 0.0375\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.0338\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 0.0308\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 0.0266\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.0232\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.0211\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 0.0536\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.0435\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 0.0416\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0394\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0378\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 0.0343\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 0.0315\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 0.0286\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 0.0255\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.0233\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 0.0556\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0444\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 16s 64ms/step - loss: 0.0436\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0424\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 0.0428\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 0.0424\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 0.0412\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0402\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0390\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 0.0375\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 0.0591\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.0444\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 0.0420\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 0.0391\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0358\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 0.0310\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 0.0272\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.0238\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0209\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0185\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 16s 64ms/step - loss: 0.0710\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 18s 72ms/step - loss: 0.0436\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 16s 66ms/step - loss: 0.0419\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 18s 72ms/step - loss: 0.0390\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 16s 66ms/step - loss: 0.0358\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 19s 79ms/step - loss: 0.0325\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 18s 73ms/step - loss: 0.0297\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 17s 70ms/step - loss: 0.0270\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 24s 96ms/step - loss: 0.0238\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 19s 78ms/step - loss: 0.0210\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 17s 67ms/step - loss: 0.0509\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 17s 68ms/step - loss: 0.0433\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 16s 66ms/step - loss: 0.0424\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 17s 68ms/step - loss: 0.0391\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 22s 87ms/step - loss: 0.0369\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 0.0333\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 16s 66ms/step - loss: 0.0298\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 18s 72ms/step - loss: 0.0270\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 17s 67ms/step - loss: 0.0246\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 19s 75ms/step - loss: 0.0228\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 19s 78ms/step - loss: 0.0563\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 0.0443\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 20s 80ms/step - loss: 0.0433\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 20s 80ms/step - loss: 0.0429\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 20s 80ms/step - loss: 0.0416\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 0.0407\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.0382\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 20s 80ms/step - loss: 0.0356\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 0.0329\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 0.0297\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 22s 88ms/step - loss: 0.0647\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 22s 88ms/step - loss: 0.0456\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 22s 91ms/step - loss: 0.0430\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 22s 91ms/step - loss: 0.0435\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 27s 109ms/step - loss: 0.0421\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 0.0409\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 35s 143ms/step - loss: 0.0401\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 29s 116ms/step - loss: 0.0381\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.0359\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 23s 91ms/step - loss: 0.0338\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 26s 107ms/step - loss: 0.0652\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.0445\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 34s 136ms/step - loss: 0.0443\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 27s 109ms/step - loss: 0.0436\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 28s 111ms/step - loss: 0.0475\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 23s 91ms/step - loss: 0.0467\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 22s 90ms/step - loss: 0.0436\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 27s 111ms/step - loss: 0.0437\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 26s 107ms/step - loss: 0.0438\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 24s 95ms/step - loss: 0.0436\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 28s 112ms/step - loss: 0.0535\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 27s 111ms/step - loss: 0.0433\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 26s 103ms/step - loss: 0.0432\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 26s 104ms/step - loss: 0.0414\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 26s 103ms/step - loss: 0.0391\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 25s 103ms/step - loss: 0.0359\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 26s 104ms/step - loss: 0.0321\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 26s 104ms/step - loss: 0.0299\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 26s 107ms/step - loss: 0.0284\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 26s 103ms/step - loss: 0.0249\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 28s 111ms/step - loss: 0.0599\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 28s 111ms/step - loss: 0.0441\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 28s 111ms/step - loss: 0.0434\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 28s 112ms/step - loss: 0.0423\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 27s 110ms/step - loss: 0.0409\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 28s 111ms/step - loss: 0.0386\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 28s 112ms/step - loss: 0.0356\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 28s 111ms/step - loss: 0.0327\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 28s 111ms/step - loss: 0.0300\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 28s 112ms/step - loss: 0.0267\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0735\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 27s 109ms/step - loss: 0.0449\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0441\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0431\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0430\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0407\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0394\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0370\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0350\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 27s 107ms/step - loss: 0.0316\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 30s 120ms/step - loss: 0.0527\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.0447\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 28s 115ms/step - loss: 0.0441\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.0434\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.0430\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.0429\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.0416\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.0402\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 29s 116ms/step - loss: 0.0390\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 28s 115ms/step - loss: 0.0376\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 0.0689\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 0.0447\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.0441\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.0447\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 30s 122ms/step - loss: 0.0425\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.0426\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 30s 120ms/step - loss: 0.0425\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.0419\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 30s 120ms/step - loss: 0.0406\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.0400\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 34s 137ms/step - loss: 0.0680\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 32s 127ms/step - loss: 0.0440\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 32s 128ms/step - loss: 0.0448\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 33s 133ms/step - loss: 0.0436\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 32s 128ms/step - loss: 0.0434\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 32s 129ms/step - loss: 0.0434\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 32s 128ms/step - loss: 0.0433\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 32s 127ms/step - loss: 0.0429\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 32s 128ms/step - loss: 0.0414\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 31s 127ms/step - loss: 0.0412\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 7.6711\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 0.0502\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 0.0452\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 0.0448\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 8s 32ms/step - loss: 0.0463\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 0.0460\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 0.0464\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 0.0455\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 0.0452\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 0.0455\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 10s 39ms/step - loss: 8.4604\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 0.0476\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 10s 39ms/step - loss: 0.0464\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 0.0454\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 0.0475\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 11s 44ms/step - loss: 0.0460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "248/248 [==============================] - 10s 39ms/step - loss: 0.0475\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.0469\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 0.0449\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 10s 39ms/step - loss: 0.0458\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 4.1634\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 0.0521\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.0430\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.0428\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.0428\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 0.0428\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.0428\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 0.0428\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.0428\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 0.0428\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 5.2979\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 0.0468\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.0438\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 50ms/step - loss: 0.0439\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0448\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0447\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0448\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 13s 51ms/step - loss: 0.0452\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 50ms/step - loss: 0.0445\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0448\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 24.4195\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0516\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 50ms/step - loss: 0.0543\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.0451\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0445\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0439\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0446\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.0435\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0446\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 13s 51ms/step - loss: 0.0465\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 12.1826\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.0481\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.0475\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.0448\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.0461\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.0462\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.0465\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.0479\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.0464\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.0476\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 50ms/step - loss: 14.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.0474\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0453\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0461\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0444\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.0445\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0447\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0450\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.0443\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.0452\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 3.8090\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 0.0480\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 0.0461\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 0.0448\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.0441\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 0.0451\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 0.0441\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 0.0450\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.5286\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.7443\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 27.8421\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0448\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0443\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 0.0445\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0437\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 0.2618\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 1.0442\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 0.0435\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0428\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 0.0428\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 29.6633\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0460\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 0.0454\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 16s 64ms/step - loss: 0.0449\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0451\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0477\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0470\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0461\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0474\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 0.0461\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 17s 70ms/step - loss: 39.9489\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 18s 72ms/step - loss: 0.1065\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 18s 71ms/step - loss: 0.0607\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 18s 71ms/step - loss: 0.0461\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 18s 72ms/step - loss: 0.0432\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 18s 71ms/step - loss: 0.0428\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 18s 74ms/step - loss: 0.0428\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 18s 72ms/step - loss: 0.0428\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 18s 73ms/step - loss: 0.0428\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 18s 71ms/step - loss: 0.0428\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 30.4734\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.0463\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.0463\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.0455\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 0.0447\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 0.0454\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 19s 79ms/step - loss: 0.0465\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 20s 79ms/step - loss: 0.0459\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 0.0453\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 19s 78ms/step - loss: 0.0459\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 25s 99ms/step - loss: 16.5492\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 25s 99ms/step - loss: 0.0445\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 25s 99ms/step - loss: 0.0455\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 24s 99ms/step - loss: 0.0450\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 25s 99ms/step - loss: 0.0449\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 24s 98ms/step - loss: 0.0463\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 24s 97ms/step - loss: 0.0452\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 24s 99ms/step - loss: 0.0460\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 25s 99ms/step - loss: 0.0461\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 25s 100ms/step - loss: 0.0468\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 26s 107ms/step - loss: 21.9114\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 27s 107ms/step - loss: 0.0448\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 27s 107ms/step - loss: 0.0448\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 27s 107ms/step - loss: 0.0453\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0451\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.0442\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 27s 108ms/step - loss: 0.0437\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.0450\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 27s 109ms/step - loss: 0.0440\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 27s 107ms/step - loss: 0.0450\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 37.2065\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.0476\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.0489\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.0466\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.0451\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.0451\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.0443\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.0456\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.0454\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.0449\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 29s 119ms/step - loss: 16.0367\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 28s 115ms/step - loss: 0.0633\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.0480\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.0466\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 30s 123ms/step - loss: 0.0448\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 29s 118ms/step - loss: 0.0459\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.0457\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.0455\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 28s 115ms/step - loss: 0.0448\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.0460\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 31s 123ms/step - loss: 98.3394\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.2842\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 29s 117ms/step - loss: 0.1964\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.1260\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 29s 116ms/step - loss: 0.1548\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.1139\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 29s 115ms/step - loss: 0.0803\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 28s 115ms/step - loss: 0.0468\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 29s 116ms/step - loss: 0.0431\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 28s 115ms/step - loss: 0.0431\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 32s 130ms/step - loss: 133.3642\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 30s 123ms/step - loss: 0.0612\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 30s 123ms/step - loss: 0.0622\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.0520\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 0.0483\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 32s 128ms/step - loss: 0.0499\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 0.0483\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 30s 123ms/step - loss: 0.0465\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 30s 123ms/step - loss: 0.0456\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 30s 122ms/step - loss: 166.9709\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 233396.1094\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 8s 33ms/step - loss: 0.6471\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 0.5541\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 0.4531\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 0.3551\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 0.2677\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 7s 28ms/step - loss: 0.1953\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 0.1396\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 7s 28ms/step - loss: 0.1000\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 0.0740\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 9s 37ms/step - loss: 5246542.5000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 9s 38ms/step - loss: 0.7162\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 9s 37ms/step - loss: 0.6930\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 9s 37ms/step - loss: 0.6637\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 9s 38ms/step - loss: 0.6292\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 9s 37ms/step - loss: 0.5901\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 9s 38ms/step - loss: 0.5473\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 9s 38ms/step - loss: 0.5016\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 9s 37ms/step - loss: 0.4537\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 9s 38ms/step - loss: 0.4047\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 3270343.7500\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 10s 39ms/step - loss: 0.7653\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.7336\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.6941\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.6482\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.5973\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.5425\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.4854\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.4274\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 0.3698\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 4262957.5000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.7190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.6931\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.6605\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.6224\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.5797\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.5332\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.4840\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.4331\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.3818\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 20773058.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.7285\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.7163\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.7006\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.6816\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.6594\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.6342\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.6061\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.5752\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 0.5417\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 8875558.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.5930\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.5784\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.5596\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.5371\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.5114\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.4828\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 0.4515\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.4181\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.3830\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1651756.6250\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.6636\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.6258\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.5795\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.5272\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 0.4709\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.4128\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.3548\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.2989\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 0.2467\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 16129350.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.7128\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.6995\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.6823\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 0.6617\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 0.6378\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.6107\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.5806\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.5477\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 0.5123\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 13s 51ms/step - loss: 7283967.5000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 0.8474\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 13s 51ms/step - loss: 0.8235\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 0.7932\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 0.7572\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 13s 51ms/step - loss: 0.7161\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 0.6707\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 13s 51ms/step - loss: 0.6214\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 0.5692\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 13s 51ms/step - loss: 0.5148\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 195600464.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 0.8097\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 0.8052\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 0.7994\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 0.7923\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 0.7838\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 0.7739\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 0.7625\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 0.7495\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 0.7349\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 18s 74ms/step - loss: 48224788.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 18s 71ms/step - loss: 0.7218\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 17s 70ms/step - loss: 0.7139\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 17s 70ms/step - loss: 0.7036\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 17s 70ms/step - loss: 0.6911\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 17s 70ms/step - loss: 0.6763\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 17s 71ms/step - loss: 0.6593\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 18s 71ms/step - loss: 0.6400\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 17s 71ms/step - loss: 0.6183\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 17s 70ms/step - loss: 0.5944\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 149696656.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 39367.8555\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 0.5964\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 0.5916\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 19s 76ms/step - loss: 0.5857\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 19s 78ms/step - loss: 0.5788\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 0.5706\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 0.5613\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 0.5507\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 19s 77ms/step - loss: 0.5388\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 25s 99ms/step - loss: 3524290.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 25s 99ms/step - loss: 0.7131\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 24s 97ms/step - loss: 0.6848\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 24s 97ms/step - loss: 0.6494\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 24s 98ms/step - loss: 0.6081\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 24s 97ms/step - loss: 0.5621\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 24s 98ms/step - loss: 0.5126\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 24s 97ms/step - loss: 0.4607\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 24s 97ms/step - loss: 0.4077\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 25s 99ms/step - loss: 0.3549\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 69361176.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.7385\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 26s 104ms/step - loss: 0.7318\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.7230\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.7123\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 26s 104ms/step - loss: 0.6996\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 26s 107ms/step - loss: 0.6850\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.6683\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.6495\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 26s 104ms/step - loss: 0.6285\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 41285472.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 26s 104ms/step - loss: 0.7846\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.7752\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.7630\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.7482\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.7308\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.7107\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 26s 106ms/step - loss: 0.6880\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.6627\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 26s 105ms/step - loss: 0.6348\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 27584890.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.9015\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 29s 116ms/step - loss: 0.8883\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.8712\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.8505\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.8263\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.7986\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 28s 112ms/step - loss: 0.7675\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.7331\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.6954\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 30s 120ms/step - loss: 48615260.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.7235\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.7156\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.7054\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.6930\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 28s 113ms/step - loss: 0.6783\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.6614\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.6422\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.6208\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 28s 114ms/step - loss: 0.5970\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 544312832.0000\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.7301\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.7277\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 0.7245\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 30s 122ms/step - loss: 0.7207\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.7160\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 30s 122ms/step - loss: 0.7106\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 0.7043\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 30s 122ms/step - loss: 0.6971\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 30s 122ms/step - loss: 0.6889\n",
      "Best learning rate: 0.01\n",
      "Best number of filters: 32\n",
      "Best filter size: (3, 3)\n",
      "Best number of dense layers: 3\n",
      "Best MSE: 0.04500601888541913\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters to experiment with\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "num_filters = [32, 64, 128]\n",
    "filter_sizes = [(3, 3), (5, 5), (7, 7)]\n",
    "num_dense_layers = [2, 3]\n",
    "\n",
    "# Initialize variables to store best hyperparameters and performance\n",
    "best_learning_rate = None\n",
    "best_num_filters = None\n",
    "best_filter_size = None\n",
    "best_num_dense_layers = None\n",
    "best_mse = float(\"inf\")\n",
    "\n",
    "# Iterate over hyperparameters\n",
    "for lr in learning_rates:\n",
    "    for filters in num_filters:\n",
    "        for size in filter_sizes:\n",
    "            for dense_layers in num_dense_layers:\n",
    "                # Create the CNN model\n",
    "                model = tf.keras.Sequential()\n",
    "                model.add(layers.Conv2D(filters, size, activation=\"relu\", input_shape=(64, 64, 3)))\n",
    "                model.add(layers.MaxPooling2D((2, 2)))\n",
    "                for _ in range(dense_layers):\n",
    "                    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "                model.add(layers.Flatten())\n",
    "                model.add(layers.Dense(1, activation=\"linear\"))\n",
    "                \n",
    "                # Compile the model\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                model.compile(optimizer=optimizer, loss=\"mean_squared_error\")\n",
    "                \n",
    "                # Train the model\n",
    "                model.fit(x_train, y_train, epochs=10, verbose=1)\n",
    "                \n",
    "                # Evaluate the model on the validation set\n",
    "                y_pred = model.predict(x_test)\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                \n",
    "                # Check if this configuration is the best so far\n",
    "                if mse < best_mse:\n",
    "                    best_learning_rate = lr\n",
    "                    best_num_filters = filters\n",
    "                    best_filter_size = size\n",
    "                    best_num_dense_layers = dense_layers\n",
    "                    best_mse = mse\n",
    "\n",
    "# Print the best hyperparameters and performance\n",
    "print(\"Best learning rate:\", best_learning_rate)\n",
    "print(\"Best number of filters:\", best_num_filters)\n",
    "print(\"Best filter size:\", best_filter_size)\n",
    "print(\"Best number of dense layers:\", best_num_dense_layers)\n",
    "print(\"Best MSE:\", best_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then use the hyperparameters that give us best MSE to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 472.8375 - val_loss: 444.1030\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 429.2018 - val_loss: 455.7831\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 23s 94ms/step - loss: 421.3218 - val_loss: 449.4141\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 30s 121ms/step - loss: 410.8760 - val_loss: 451.6507\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 17s 68ms/step - loss: 395.7093 - val_loss: 455.0119\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 17s 68ms/step - loss: 371.9485 - val_loss: 469.7047\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 22s 89ms/step - loss: 341.0912 - val_loss: 494.4971\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 20s 80ms/step - loss: 303.2315 - val_loss: 527.5176\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 18s 72ms/step - loss: 252.2645 - val_loss: 541.3567\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 17s 69ms/step - loss: 206.2627 - val_loss: 580.8371\n"
     ]
    }
   ],
   "source": [
    "# Create the CNN model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add the convolutional layers\n",
    "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "\n",
    "# Add the fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"linear\"))  # Output layer with linear activation for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 11ms/step - loss: 580.8371\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of the y_test\n",
    "plt.hist(y_test, bins=30, edgecolor='black')\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of y_test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEXCAYAAABCjVgAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAcGklEQVR4nO3de5QdVZn38e+PJArhFjAthCSdBiYyIDMGaBFfQKMw8wITZHBAYCEGBgiugQFHZg0XUdB3eF+d4aKMM2CQyEXkGrnIoBgYJDqLi+EeCAwXQ9JJJ2mCEG4CCc/7R+1THjrnpKtDn1PdfX6ftc7qql27qp6uVPo5tXfVLkUEZmZmABuUHYCZmQ0eTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUrlaRLJH19gLbVLuk1SSPS/K8kHTcQ207b+7mk6QO1vX7s958lvShpWbP3vb4kLZS0b9lxWP+NLDsAG74kLQS2AlYDa4AngSuBmRHxLkBEfLkf2zouIu6sVyciFgGbvL+o8/2dA/xJRHyxavv7D8S2+xnHROBUYFJErGj2/q31+ErBGu3AiNgUmAR8GzgNuGygdyJpuH7BmQSsLDMhDONjazU4KVhTRMQrEXErcBgwXdLOAJIul/TPaXqspNskvSzpJUm/lrSBpKuAduBnqXnonyR1SApJx0paBPxXVVn1H7HtJT0g6RVJt0jaMu1rqqSu6hgrTR6S9gPOBA5L+3s0Lc+bo1JcZ0l6QdIKSVdK2jwtq8QxXdKi1PTztXrHRtLmaf2etL2z0vb3BeYA26Q4Lq+x7nxJB1bNj0r7m7KO/VXimyFpqaRuSadWLT9H0o2SfixpFXB0iud0Sc9JWinp+sqxTOsclWJfua7f1QY/JwVrqoh4AOgC9q6x+NS0rI2s2enMbJU4ClhEdtWxSUT8S9U6nwZ2BP53nV1+CfhbYBuyZqyLCsT4C+D/Atel/X2sRrWj0+czwHZkzVbf71VnL2AHYB/gG5J2rLPLfwM2T9v5dIr5mNRUtj+wNMVxdI11rwS+WDV/ANAdEY/08WuSYp8M/CVweq8+gIOAG4ExwNXAycBfp/i2AX4P/DuApJ2Ai4Gj0rIPARMK7N8GIScFK8NSYMsa5e8A48jaz9+JiF9H34NznRMRr0fEm3WWXxUR8yPideDrwBcqHdHv05HABRHxfES8BpwBHN7rKuWbEfFmRDwKPAqslVxSLIcBZ0TEqxGxEDif7A9sET8GDpC0WZo/Criq4LrfTMfuceBHwBFVy+6NiJsj4t10bE8AvhYRXRHxFnAOcEj6fQ8BbouIuWnZ14F3C8Zgg4yTgpVhPPBSjfJ/BZ4FfinpeUmnF9jW4n4sfwEYBYwtFOW6bZO2V73tkWRXOBXVdwu9Qe1O8LHAB2psa3yRICJiKfDfwN9IGkN2ZXF1kXVZ+9hsU2cZZH0bN6WmvZeBBWQ3D2yV1svrpwS8smAMNsg4KVhTSfo42R+83/Relr4pnxoR2wEHAl+VtE9lcZ1N9nUlMbFqup3sauRF4HVgdFVcI8iarYpudynZH8rqba8GlvexXm8vpph6b2tJP7ZxBVkT0qFk3/CLrtv72Cytmu/9+y8G9o+IMVWfDdO+uqu3JWk0WROSDUFOCtYUkjaTNA24FvhxarLoXWeapD+RJGAV2TfRNWnxcrI29/76oqSd0h+qbwE3RsQa4H+ADSX9laRRwFnAB6vWWw50SKr3f+Qa4B8kbStpE/7YB7G6P8GlWK4HzpW0qaRJwFfJmoWKuhnYFTiFrI+hqK9LGi3po8AxwHXrqHtJinESgKQ2SQelZTcC0yTtJekDZMfZf1uGKP/DWaP9TNKrZN80vwZcQPYHqJbJwJ3Aa8C9wH9ExK/Ssv8HnJWaL/6xH/u/CricrClnQ7IOUyLiFeDvgB+SfSt/nayTu+KG9HOlpIdqbHdW2vZc4HfAH4C/70dc1f4+7f95siuon6TtF5La/GcD2wI/7cd+7yFrrrsLOC8ifrmOut8DbiVr2nsVuA/4RNr/E8CJKe5usk7orjrbsUFOfsmO2dAn6RvAR6oftltH3Q6yRDaqv1c2Nvz5oRSzIS49L3Asxe9YMqvLzUdmQ5ik48ma5n4eEXOryo9MD7z1/jxRXrQ2FLj5yMzMcr5SMDOz3JDuUxg7dmx0dHSUHYaZ2ZDy4IMPvhgRbbWWDemk0NHRwbx588oOw8xsSJH0Qr1lbj4yM7Ncw5KCpImS7pa0QNITkk5J5VtKmiPpmfRzi1QuSRdJelbSY5J2bVRsZmZWWyOvFFYDp0bEjsAewIlpiN3TgbsiYjLZk5SVQc/2J3uidTIwg2woXjMza6KGJYWI6I6Ih9L0q2SjKo4nG6f9ilTtCrIx2knlV0bmPmCMpHGNis/MzNbWlD6F9Fj9LsD9wFYR0Q1Z4gA+nKqN573D9XZRcPhgMzMbGA1PCmkEydnAVyJi1bqq1ihb68m69ArBeZLm9fT0DFSYZmZGg5NCGpJ4NnB1RFRGb1xeaRZKPysvJO/iveO7T+C947sDEBEzI6IzIjrb2mreZmtmZuupkXcfCbgMWBARF1QtuhWYnqanA7dUlX8p3YW0B/BKpZnJzMyao5EPr+1JNmrj45IqLxE/E/g2cL2kY8lexn5oWnY72UvHnyV7dWG9MffNzKxBGpYUIuI31O4nANind0F6QfuJjYrHyjVuQjvLlvT1OmXYevxEursWNSEiM6tlSA9zYUPHsiWLmXTabX3We+E705oQjZnV42EuzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFG1xGjEJSn59xE9rLjtRsWPLYRza4rHnHYySZlchXCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZrmGJQVJsyStkDS/quw6SY+kz8LKu5sldUh6s2rZJY2Ky8zM6mvkLamXA98HrqwURMRhlWlJ5wOvVNV/LiKmNDAeMzPrQ8OSQkTMldRRa5kkAV8APtuo/ZuZWf+V1aewN7A8Ip6pKttW0sOS7pG0d70VJc2QNE/SvJ6ensZHaus0bkJ7oSeQB5yffDZriLKeaD4CuKZqvhtoj4iVknYDbpb00YhY1XvFiJgJzATo7OyMpkRrdS1bsricJ5D95LNZQzT9SkHSSODzwHWVsoh4KyJWpukHgeeAjzQ7NjOzVldG89G+wFMR0VUpkNQmaUSa3g6YDDxfQmxmZi2tkbekXgPcC+wgqUvSsWnR4by36QjgU8Bjkh4FbgS+HBEvNSo2MzOrrZF3Hx1Rp/zoGmWzgdmNisXMzIrxE81mZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4INb37vglm/lPU+BbPm8HsXzPrFVwpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgNY2b0F7orh0zG14adveRpFnANGBFROycys4Bjgd6UrUzI+L2tOwM4FhgDXByRNzRqNisb8uWLPZdO2YtqJFXCpcD+9UovzAipqRPJSHsRPbu5o+mdf5D0ogGxmZmZjU0LClExFzgpYLVDwKujYi3IuJ3wLPA7o2KzczMaiujT+EkSY9JmiVpi1Q2HlhcVacrla1F0gxJ8yTN6+npqVXFzMzWU7OTwsXA9sAUoBs4P5XX6rGMWhuIiJkR0RkRnW1tbY2J0sysRTU1KUTE8ohYExHvApfyxyaiLmBiVdUJwNJmxmZmZk1OCpLGVc0eDMxP07cCh0v6oKRtgcnAA82MzczMGntL6jXAVGCspC7gbGCqpClkTUMLgRMAIuIJSdcDTwKrgRMjYk2jYjMzs9oalhQi4ogaxZeto/65wLmNiseyB9KWLVncd0Uza1keOruFFH0gDfxQmlmr8jAXZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzklhGBg3oR1JfX7MzPril+wMA0VfnuMX56zDiFGFE+fW4yfS3bWowQGZlaOR72ieBUwDVkTEzqnsX4EDgbeB54BjIuJlSR3AAuDptPp9EfHlRsVmtpY17/itdGY0tvnocmC/XmVzgJ0j4s+B/wHOqFr2XERMSR8nBDOzEhRKCpJ27u+GI2Iu8FKvsl9GxOo0ex8wob/bNTOzxil6pXCJpAck/Z2kMQO0778Ffl41v62khyXdI2nveitJmiFpnqR5PT09AxSKmZlBwaQQEXsBRwITgXmSfiLpL9Z3p5K+BqwGrk5F3UB7ROwCfBX4iaTN6sQyMyI6I6Kzra1tfUMwM7MaCvcpRMQzwFnAacCngYskPSXp8/3ZoaTpZB3QR0ZEpG2/FREr0/SDZJ3QH+nPds3M7P0r2qfw55IuJLtD6LPAgRGxY5q+sOjOJO1HllQ+FxFvVJW3SRqRprcDJgPPF/4tzMxsQBS9JfX7wKXAmRHxZqUwIpZKOqvWCpKuAaYCYyV1AWeT3W30QWBOuie8cuvpp4BvSVoNrAG+HBEv1dqumZk1TtGkcADwZkSsAZC0AbBhRLwREVfVWiEijqhRfFmdurOB2QVjMTOzBinap3AnsFHV/OhUZmZmw0jRpLBhRLxWmUnToxsTkpmZlaVoUnhd0q6VGUm7AW+uo76ZmQ1BRfsUvgLcIGlpmh8HHNaYkMzMrCyFkkJE/FbSnwI7AAKeioh3GhqZmZk1XX9GSf040JHW2UUSEXFlQ6IyM7NSFEoKkq4CtgceIXuOACAAJwUzs2Gk6JVCJ7BTZVgKMzMbnorefTQf2LqRgZiZWfmKXimMBZ6U9ADwVqUwIj7XkKjMzKwURZPCOY0MwszMBoeit6TeI2kSMDki7pQ0GhjR2NDMzKzZig6dfTxwI/CDVDQeuLlRQZmZWTmKdjSfCOwJrIL8hTsfblRQZmZWjqJJ4a2IeLsyI2kk2XMKZmY2jBRNCvdIOhPYKL2b+QbgZ40Ly8zMylA0KZwO9ACPAycAt5O9r9nMzIaRQkkhIt6NiEsj4tCIOCRN99l8JGmWpBWS5leVbSlpjqRn0s8tUrkkXSTpWUmPVQ/VbWZmzVH07qPfSXq+96fAqpcD+/UqOx24KyImA3eleYD9gcnpMwO4uEhsZmY2cPoz9lHFhsChwJZ9rRQRcyV19Co+CJiapq8AfgWclsqvTFcg90kaI2lcRHQXjNHMzN6nos1HK6s+SyLiu8Bn13OfW1X+0KeflVtbxwOLq+p1pbL3kDRD0jxJ83p6etYzBDMzq6Xo0NnV7fsbkF05bDrAsahG2Vr9FhExE5gJ0NnZ6dtizcwGUNHmo/OrplcDC4EvrOc+l1eahSSNA1ak8i5gYlW9CcDStdY2M7OGKTr20WcGcJ+3AtOBb6eft1SVnyTpWuATwCvuTzAza66izUdfXdfyiLigznrXkHUqj5XUBZxNlgyul3QssIis0xqyZx8OAJ4F3gCOKRKbmZkNnP7cffRxsm/zAAcCc3lvx/BaIuKIOov2qVE3yMZYMjOzkvTnJTu7RsSrAJLOAW6IiOMaFZiZmTVf0WEu2oG3q+bfBjoGPBozMytV0SuFq4AHJN1EdpvowcCVDYvKzMxKUfTuo3Ml/RzYOxUdExEPNy4sMzMrQ9HmI4DRwKqI+B7QJWnbBsVkZmYlKTog3tlk4xOdkYpGAT9uVFBmZlaOolcKBwOfA14HiIilDPwwF9bLuAntSOrzY2Y2UIp2NL8dESEpACRt3MCYLFm2ZDGTTrutz3ovfGdaE6Ixs1ZQ9Erhekk/AMZIOh64E7i0cWGZmVkZit59dF56N/MqYAfgGxExp6GRmZlZ0/WZFCSNAO6IiH0BJwIzs2Gsz+ajiFgDvCFp8ybEY2ZmJSra0fwH4HFJc0h3IAFExMkNicrMzEpRNCn8Z/qYmdkwts6kIKk9IhZFxBXNCshs0BsxqtDzIVuPn0h316ImBGQ2cPq6UrgZ2BVA0uyI+JvGh2Q2yK15p9jzI+cd7ORhQ05fSaH6jN6ukYGYDTtFk4cfPrRBpK+kEHWm15ukHYDrqoq2A74BjAGOB3pS+ZkRcftA7NPMzIrpKyl8TNIqsiuGjdI0aT4iYrP+7jAingamQP4MxBLgJrJ3Ml8YEef1d5tmZjYw1pkUImJEg/e/D/BcRLzggd3MzMrXn/cpNMLhwDVV8ydJekzSLElblBWUmVmrKi0pSPoA2XDcN6Sii4HtyZqWuoHz66w3Q9I8SfN6enpqVTEzs/VU5pXC/sBDEbEcICKWR8SaiHiXbATW3WutFBEzI6IzIjrb2tqaGK6Z2fBXZlI4gqqmI0njqpYdDMxvekRmZi2u6DAXA0rSaOAvgBOqiv9F0hSyW18X9lpmZmZNUEpSiIg3gA/1KjuqjFjMzOyPyr77yMzMBhEnBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLlfI6TgBJC4FXgTXA6ojolLQlcB3QQfae5i9ExO/LitHMrNWUfaXwmYiYEhGdaf504K6ImAzclebNhrcRo5DU52fchPayI7UWUNqVQh0HAVPT9BXAr4DTygqmUcZNaGfZksVlh2GDxZp3mHTabX1We+E705oQjLW6MpNCAL+UFMAPImImsFVEdANERLekD/deSdIMYAZAe/vQ/Oa0bMli/xEws0GpzKSwZ0QsTX/450h6qshKKXnMBOjs7IxGBmhm1mpK61OIiKXp5wrgJmB3YLmkcQDp54qy4jMza0WlJAVJG0vatDIN/CUwH7gVmJ6qTQduKSM+M7NWVVbz0VbATZIqMfwkIn4h6bfA9ZKOBRYBh5YUn5lZSyolKUTE88DHapSvBPZpfkRmZgblP6dgZmaDiJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAbKvzeBWuCwfY+BTOrx+9dsCbwlYKZmeWcFMzMLOekYGZmOSeFATRuQnuhjkAzs8HKHc0DyO9eNrOhzlcKZmaWc1IwM7Nc05OCpImS7pa0QNITkk5J5edIWiLpkfQ5oNmxmZm1ujL6FFYDp0bEQ5I2BR6UNCctuzAizishJjMzo4SkEBHdQHeaflXSAmB8s+MwM7O1ldqnIKkD2AW4PxWdJOkxSbMkbVFnnRmS5kma19PT06RIzcxaQ2lJQdImwGzgKxGxCrgY2B6YQnYlcX6t9SJiZkR0RkRnW1tb0+I1M2sFpSQFSaPIEsLVEfFTgIhYHhFrIuJd4FJg9zJiMzNrZWXcfSTgMmBBRFxQVT6uqtrBwPxmx2Y2LHiIbXsfyrj7aE/gKOBxSY+ksjOBIyRNAQJYCJxQQmw1jZvQzrIli8sOw6wYD7Ft70MZdx/9Bqg1ANDtzY6lKA9fYWatwk80m5lZzknBzNap6Oi/7qcYHjxKqpmtU9HmU3AT6nDgKwUzM8s5KZiZWc7NR2atKj3PYFbNScGsVfl5BqvBzUdmZpZzUjAzs5yTgpmZ5ZwUzGzgeDC+Ia+lO5o90J3ZAHPn9ZDX0knBA92Zmb2Xm4/MzCznpGBmZjknBTNrPndID1ot3adgZiVxh/Sg5SsFMzPLDbqkIGk/SU9LelbS6WXHY2bWSgZVUpA0Avh3YH9gJ+AISTuVG5WZDXZF3w438oMbDWi94djnMdj6FHYHno2I5wEkXQscBDxZalRmVo5+DO9dtI9ioOsNtKIP1W49fiLdXYsGfP+KiAHf6PqSdAiwX0Qcl+aPAj4RESdV1ZkBzEizOwBPNz3Q/hsLvFh2EIOUj019Pjb1+djUV+TYTIqItloLBtuVQq2vBO/JWhExE5jZnHAGhqR5EdFZdhyDkY9NfT429fnY1Pd+j82g6lMAuoCJVfMTgKUlxWJm1nIGW1L4LTBZ0raSPgAcDtxackxmZi1jUDUfRcRqSScBdwAjgFkR8UTJYQ2EIdXc1WQ+NvX52NTnY1Pf+zo2g6qj2czMyjXYmo/MzKxETgpmZpZzUhhgkiZKulvSAklPSDollW8paY6kZ9LPLcqOtQySRkh6WNJtaX5bSfen43JdusGg5UgaI+lGSU+lc+eTPmcykv4h/V+aL+kaSRu26nkjaZakFZLmV5XVPE+UuSgNGfSYpF2L7MNJYeCtBk6NiB2BPYAT01AdpwN3RcRk4K4034pOARZUzX8HuDAdl98Dx5YSVfm+B/wiIv4U+BjZMWr5c0bSeOBkoDMidia7AeVwWve8uRzYr1dZvfNkf2By+swALi6yAyeFARYR3RHxUJp+lew/93iy4TquSNWuAP66nAjLI2kC8FfAD9O8gM8CN6YqrXpcNgM+BVwGEBFvR8TL+JypGAlsJGkkMBropkXPm4iYC7zUq7jeeXIQcGVk7gPGSBrX1z6cFBpIUgewC3A/sFVEdEOWOIAPlxdZab4L/BPwbpr/EPByRKxO811kCbTVbAf0AD9KTWs/lLQxPmeIiCXAecAismTwCvAgPm+q1TtPxgPVgygVOk5OCg0iaRNgNvCViFhVdjxlkzQNWBERD1YX16jaivdIjwR2BS6OiF2A12nBpqJaUvv4QcC2wDbAxmTNIr214nnTl/X6/+Wk0ACSRpElhKsj4qepeHnl0i39XFFWfCXZE/icpIXAtWSX/98lu6StPETZqsOadAFdEXF/mr+RLEm0+jkDsC/wu4joiYh3gJ8C/wufN9XqnSfrNWyQk8IAS+3klwELIuKCqkW3AtPT9HTglmbHVqaIOCMiJkREB1lH4X9FxJHA3cAhqVrLHReAiFgGLJa0Qyrah2y4+JY+Z5JFwB6SRqf/W5Vj0/LnTZV658mtwJfSXUh7AK9UmpnWxU80DzBJewG/Bh7nj23nZ5L1K1wPtJOd6IdGRO8Oo5YgaSrwjxExTdJ2ZFcOWwIPA1+MiLfKjK8MkqaQdcB/AHgeOIbsS1vLnzOSvgkcRnZn38PAcWRt4y133ki6BphKNjz2cuBs4GZqnCcpiX6f7G6lN4BjImJen/twUjAzswo3H5mZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYDaISOqoHhbZrNmcFMyaQNKIsmMwK8JJwawGSf+n8oKkNH+upJNr1Jsqaa6kmyQ9KekSSRukZa9J+pak+4FPStpN0j2SHpR0R9V4NbtJelTSvcCJzfodzWpxUjCr7TLSeDLpj/zhwNV16u4OnAr8GbA98PlUvjEwPyI+QTbMyb8Bh0TEbsAs4NxU70fAyRHxyQb8Hmb9MrLvKmatJyIWSlopaRdgK+DhiFhZp/oDEfE85GPT7EU20ukastFyAXYAdgbmZEPSMALolrQ5MCYi7kn1rqL20NBmTeGkYFbfD4Gjga3JvtnX03sAscr8HyJiTZoW8ETvqwFJY2qsb1YaNx+Z1XcT2QiTHwfuWEe93dOL5DcgG83zNzXqPA20SfokZO/ckPTR9NrNV9LougBHDlz4Zv3nKwWzOiLibUl3k736cc06qt4LfJusT2EuWTKpta1DgItSk9FIspcMPUE2TPYsSW+w7uRj1nAeOtusjvTN/yGy8emfqVNnKundEM2MzaxR3HxkVoOknYBngbvqJQSz4chXCmYFSPozsjuDqr2Vbjc1GzacFMzMLOfmIzMzyzkpmJlZzknBzMxyTgpmZpb7/+dfzlkw+G8TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of the y_test\n",
    "plt.hist(y_pred, bins=30, edgecolor='black')\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the category boundaries\n",
    "boundaries = [20, 40, 60, 80]\n",
    "\n",
    "# Categorize y_test and y_pred\n",
    "y_test_categories = np.digitize(y_test, boundaries)\n",
    "y_pred_categories = np.digitize(y_pred, boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1: Accuracy = 0.5189\n",
      "Category 2: Accuracy = 0.5270\n",
      "Category 3: Accuracy = 0.8699\n",
      "Category 4: Accuracy = 0.9314\n",
      "Category 5: Accuracy = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for each category\n",
    "category_accuracy = []\n",
    "for category in range(1, 6):\n",
    "    y_test_category = (y_test_categories == category)\n",
    "    y_pred_category = (y_pred_categories == category)\n",
    "    accuracy = accuracy_score(y_test_category, y_pred_category)\n",
    "    category_accuracy.append(accuracy)\n",
    "\n",
    "# Print the accuracy for each category\n",
    "for category, accuracy in enumerate(category_accuracy, start=1):\n",
    "    print(f\"Category {category}: Accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1:\n",
      "Precision: 0.1954\n",
      "Recall: 0.0625\n",
      "F1-Score: 0.0947\n",
      "\n",
      "Category 2:\n",
      "Precision: 0.5129\n",
      "Recall: 0.5532\n",
      "F1-Score: 0.5323\n",
      "\n",
      "Category 3:\n",
      "Precision: 0.2111\n",
      "Recall: 0.3535\n",
      "F1-Score: 0.2643\n",
      "\n",
      "Category 4:\n",
      "Precision: 0.0682\n",
      "Recall: 0.0408\n",
      "F1-Score: 0.0511\n",
      "\n",
      "Category 5:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.06      0.09       272\n",
      "           1       0.51      0.55      0.53      1005\n",
      "           2       0.21      0.35      0.26       430\n",
      "           3       0.07      0.04      0.05       147\n",
      "           4       0.00      0.00      0.00       129\n",
      "\n",
      "    accuracy                           0.37      1983\n",
      "   macro avg       0.20      0.20      0.19      1983\n",
      "weighted avg       0.34      0.37      0.34      1983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each category\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_categories, y_pred_categories)\n",
    "\n",
    "# Print precision, recall, and F1-score for each category\n",
    "for category in range(1, 6):\n",
    "    print(f\"Category {category}:\")\n",
    "    print(f\"Precision: {precision[category-1]:.4f}\")\n",
    "    print(f\"Recall: {recall[category-1]:.4f}\")\n",
    "    print(f\"F1-Score: {f1_score[category-1]:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test_categories, y_pred_categories)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat Pawpularity as a categorical variable in the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bins and labels for recoding\n",
    "bins = [0, 20, 40, 60, 80, float('inf')]\n",
    "labels = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Recode the \"Pawpularity\" column\n",
    "df[\"Rankings\"] = pd.cut(df[\"Pawpularity\"], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Convert the recoded column to integer type\n",
    "df[\"Rankings\"] = df[\"Rankings\"].astype(int)\n",
    "\n",
    "# Convert the recoded column to a NumPy array\n",
    "rankings = df[\"Rankings\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5119\n",
       "2    2088\n",
       "0    1417\n",
       "3     727\n",
       "4     561\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the frequency of each category\n",
    "rankings_series = pd.Series(rankings)\n",
    "\n",
    "rankings_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each category has similar counts, I will use accuracy in the model training process to select the best performence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(images, rankings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "248/248 [==============================] - 8s 32ms/step - loss: 1.3215 - accuracy: 0.5153 - val_loss: 1.3262 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 8s 30ms/step - loss: 1.3032 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3284 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 8s 30ms/step - loss: 1.2922 - accuracy: 0.5163 - val_loss: 1.3343 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2856 - accuracy: 0.5160 - val_loss: 1.3382 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2703 - accuracy: 0.5175 - val_loss: 1.3422 - val_accuracy: 0.5058\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2514 - accuracy: 0.5185 - val_loss: 1.3552 - val_accuracy: 0.4912\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 8s 30ms/step - loss: 1.2204 - accuracy: 0.5262 - val_loss: 1.3852 - val_accuracy: 0.4942\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 8s 30ms/step - loss: 1.1856 - accuracy: 0.5387 - val_loss: 1.3993 - val_accuracy: 0.4962\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.1388 - accuracy: 0.5484 - val_loss: 1.4355 - val_accuracy: 0.4594\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.4355 - accuracy: 0.4594\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.3204 - accuracy: 0.5153 - val_loss: 1.3216 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3022 - accuracy: 0.5163 - val_loss: 1.3207 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2988 - accuracy: 0.5163 - val_loss: 1.3359 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2943 - accuracy: 0.5163 - val_loss: 1.3218 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2919 - accuracy: 0.5163 - val_loss: 1.3233 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2790 - accuracy: 0.5163 - val_loss: 1.3397 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2646 - accuracy: 0.5163 - val_loss: 1.3459 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2446 - accuracy: 0.5162 - val_loss: 1.3539 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.2121 - accuracy: 0.5190 - val_loss: 1.4058 - val_accuracy: 0.5038\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.1728 - accuracy: 0.5296 - val_loss: 1.4165 - val_accuracy: 0.4967\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.4165 - accuracy: 0.4967\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.3201 - accuracy: 0.5153 - val_loss: 1.3274 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.3065 - accuracy: 0.5163 - val_loss: 1.3221 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3017 - accuracy: 0.5163 - val_loss: 1.3221 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 11s 42ms/step - loss: 1.2985 - accuracy: 0.5163 - val_loss: 1.3425 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.2976 - accuracy: 0.5163 - val_loss: 1.3234 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.2959 - accuracy: 0.5163 - val_loss: 1.3315 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.2923 - accuracy: 0.5163 - val_loss: 1.3231 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 11s 42ms/step - loss: 1.2864 - accuracy: 0.5165 - val_loss: 1.3264 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.3264 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.3267 - accuracy: 0.5154 - val_loss: 1.3246 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 11s 42ms/step - loss: 1.3064 - accuracy: 0.5163 - val_loss: 1.3318 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.2992 - accuracy: 0.5163 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 11s 42ms/step - loss: 1.2991 - accuracy: 0.5163 - val_loss: 1.3203 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.2988 - accuracy: 0.5163 - val_loss: 1.3202 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 11s 42ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3207 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.2984 - accuracy: 0.5163 - val_loss: 1.3220 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.2981 - accuracy: 0.5163 - val_loss: 1.3222 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.3222 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3249 - accuracy: 0.5131 - val_loss: 1.3257 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3084 - accuracy: 0.5163 - val_loss: 1.3233 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3019 - accuracy: 0.5163 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.2999 - accuracy: 0.5163 - val_loss: 1.3220 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.2970 - accuracy: 0.5163 - val_loss: 1.3337 - val_accuracy: 0.5063\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3002 - accuracy: 0.5165 - val_loss: 1.3220 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.2934 - accuracy: 0.5165 - val_loss: 1.3439 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.2932 - accuracy: 0.5167 - val_loss: 1.3342 - val_accuracy: 0.5073\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.2876 - accuracy: 0.5160 - val_loss: 1.3423 - val_accuracy: 0.5078\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.2811 - accuracy: 0.5171 - val_loss: 1.3500 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3500 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3717 - accuracy: 0.5017 - val_loss: 1.3267 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3140 - accuracy: 0.5163 - val_loss: 1.3405 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3100 - accuracy: 0.5163 - val_loss: 1.3289 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3055 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.3035 - accuracy: 0.5163 - val_loss: 1.3307 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.3021 - accuracy: 0.5163 - val_loss: 1.3342 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.3036 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.2988 - accuracy: 0.5163 - val_loss: 1.3246 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.2987 - accuracy: 0.5163 - val_loss: 1.3274 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.2989 - accuracy: 0.5163 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3210 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.3150 - accuracy: 0.5139 - val_loss: 1.3373 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.3056 - accuracy: 0.5163 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.3027 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.3007 - accuracy: 0.5163 - val_loss: 1.3221 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 46ms/step - loss: 1.2989 - accuracy: 0.5163 - val_loss: 1.3199 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2947 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2857 - accuracy: 0.5166 - val_loss: 1.3346 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2731 - accuracy: 0.5175 - val_loss: 1.3412 - val_accuracy: 0.5073\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2461 - accuracy: 0.5210 - val_loss: 1.3647 - val_accuracy: 0.4967\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2021 - accuracy: 0.5335 - val_loss: 1.4314 - val_accuracy: 0.4927\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.4314 - accuracy: 0.4927\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.3170 - accuracy: 0.5139 - val_loss: 1.3256 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 50ms/step - loss: 1.3041 - accuracy: 0.5163 - val_loss: 1.3203 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 46ms/step - loss: 1.3001 - accuracy: 0.5163 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3257 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2992 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2971 - accuracy: 0.5163 - val_loss: 1.3237 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2920 - accuracy: 0.5163 - val_loss: 1.3226 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2844 - accuracy: 0.5163 - val_loss: 1.3262 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2706 - accuracy: 0.5153 - val_loss: 1.3461 - val_accuracy: 0.5063\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2457 - accuracy: 0.5182 - val_loss: 1.3593 - val_accuracy: 0.5023\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3593 - accuracy: 0.5023\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 1.3237 - accuracy: 0.5131 - val_loss: 1.3422 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 1.3035 - accuracy: 0.5163 - val_loss: 1.3198 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3025 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3008 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3426 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.2989 - accuracy: 0.5163 - val_loss: 1.3285 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 1.2990 - accuracy: 0.5163 - val_loss: 1.3236 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.2987 - accuracy: 0.5163 - val_loss: 1.3255 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.2930 - accuracy: 0.5163 - val_loss: 1.3283 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3283 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3250 - accuracy: 0.5108 - val_loss: 1.3275 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3091 - accuracy: 0.5163 - val_loss: 1.3390 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.3012 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 1.3008 - accuracy: 0.5163 - val_loss: 1.3283 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.3012 - accuracy: 0.5163 - val_loss: 1.3197 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3018 - accuracy: 0.5163 - val_loss: 1.3284 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3024 - accuracy: 0.5163 - val_loss: 1.3235 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3007 - accuracy: 0.5163 - val_loss: 1.3331 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3028 - accuracy: 0.5163 - val_loss: 1.3239 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3023 - accuracy: 0.5163 - val_loss: 1.3265 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3265 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3271 - accuracy: 0.5142 - val_loss: 1.3294 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3082 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3034 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 20s 83ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3229 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.2999 - accuracy: 0.5163 - val_loss: 1.3250 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3233 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3208 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 20s 83ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3214 - val_accuracy: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 1.3000 - accuracy: 0.5163 - val_loss: 1.3241 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3253 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3253 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 20s 83ms/step - loss: 1.3394 - accuracy: 0.5007 - val_loss: 1.3380 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3168 - accuracy: 0.5163 - val_loss: 1.3249 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3073 - accuracy: 0.5163 - val_loss: 1.3206 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3082 - accuracy: 0.5163 - val_loss: 1.3202 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 20s 83ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3205 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3001 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 20s 83ms/step - loss: 1.2980 - accuracy: 0.5163 - val_loss: 1.3205 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.2982 - accuracy: 0.5163 - val_loss: 1.3239 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.2984 - accuracy: 0.5163 - val_loss: 1.3196 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.2979 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3223 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 87ms/step - loss: 1.3176 - accuracy: 0.5125 - val_loss: 1.3353 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3063 - accuracy: 0.5163 - val_loss: 1.3249 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3009 - accuracy: 0.5163 - val_loss: 1.3208 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3365 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3013 - accuracy: 0.5163 - val_loss: 1.3249 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3243 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2987 - accuracy: 0.5163 - val_loss: 1.3221 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2967 - accuracy: 0.5163 - val_loss: 1.3225 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.2897 - accuracy: 0.5167 - val_loss: 1.3342 - val_accuracy: 0.5058\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2750 - accuracy: 0.5170 - val_loss: 1.3367 - val_accuracy: 0.5058\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3367 - accuracy: 0.5058\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3225 - accuracy: 0.5151 - val_loss: 1.3467 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3050 - accuracy: 0.5163 - val_loss: 1.3215 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3001 - accuracy: 0.5163 - val_loss: 1.3224 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 22s 87ms/step - loss: 1.3009 - accuracy: 0.5163 - val_loss: 1.3284 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3016 - accuracy: 0.5163 - val_loss: 1.3239 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3227 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2965 - accuracy: 0.5163 - val_loss: 1.3247 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 22s 87ms/step - loss: 1.2915 - accuracy: 0.5163 - val_loss: 1.3240 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 21s 87ms/step - loss: 1.2873 - accuracy: 0.5163 - val_loss: 1.3341 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2773 - accuracy: 0.5165 - val_loss: 1.3390 - val_accuracy: 0.5063\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.3390 - accuracy: 0.5063\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3209 - accuracy: 0.5131 - val_loss: 1.3275 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3037 - accuracy: 0.5163 - val_loss: 1.3339 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3034 - accuracy: 0.5163 - val_loss: 1.3201 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3036 - accuracy: 0.5163 - val_loss: 1.3196 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3013 - accuracy: 0.5163 - val_loss: 1.3194 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3237 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 34s 135ms/step - loss: 1.2990 - accuracy: 0.5163 - val_loss: 1.3211 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 33s 133ms/step - loss: 1.2992 - accuracy: 0.5163 - val_loss: 1.3222 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 2s 32ms/step - loss: 1.3222 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 35s 142ms/step - loss: 1.3241 - accuracy: 0.5134 - val_loss: 1.3281 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 33s 133ms/step - loss: 1.3020 - accuracy: 0.5163 - val_loss: 1.3245 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 33s 135ms/step - loss: 1.3013 - accuracy: 0.5163 - val_loss: 1.3207 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 33s 133ms/step - loss: 1.3034 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 34s 137ms/step - loss: 1.3008 - accuracy: 0.5163 - val_loss: 1.3197 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 33s 134ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 32s 130ms/step - loss: 1.2993 - accuracy: 0.5163 - val_loss: 1.3208 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 34s 137ms/step - loss: 1.2990 - accuracy: 0.5163 - val_loss: 1.3211 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 34s 136ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3363 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 33s 132ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3224 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 2s 32ms/step - loss: 1.3224 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 47s 191ms/step - loss: 1.3310 - accuracy: 0.5147 - val_loss: 1.3398 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 50s 201ms/step - loss: 1.3039 - accuracy: 0.5163 - val_loss: 1.3225 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 47s 192ms/step - loss: 1.3039 - accuracy: 0.5163 - val_loss: 1.3239 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 51s 206ms/step - loss: 1.3046 - accuracy: 0.5163 - val_loss: 1.3229 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 47s 190ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3281 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 48s 192ms/step - loss: 1.3016 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 60s 240ms/step - loss: 1.3016 - accuracy: 0.5163 - val_loss: 1.3189 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 63s 252ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3197 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 52s 210ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 48s 193ms/step - loss: 1.3015 - accuracy: 0.5163 - val_loss: 1.3268 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.3268 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 49s 197ms/step - loss: 1.3372 - accuracy: 0.5108 - val_loss: 1.3373 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 51s 205ms/step - loss: 1.3014 - accuracy: 0.5163 - val_loss: 1.3276 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 50s 203ms/step - loss: 1.3016 - accuracy: 0.5163 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 48s 193ms/step - loss: 1.3011 - accuracy: 0.5163 - val_loss: 1.3244 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 46s 185ms/step - loss: 1.3021 - accuracy: 0.5163 - val_loss: 1.3201 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 47s 190ms/step - loss: 1.3011 - accuracy: 0.5163 - val_loss: 1.3201 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 53s 213ms/step - loss: 1.2989 - accuracy: 0.5163 - val_loss: 1.3226 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 49s 198ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3247 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 49s 196ms/step - loss: 1.2995 - accuracy: 0.5163 - val_loss: 1.3207 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 47s 189ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3253 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 3s 49ms/step - loss: 1.3253 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.3430 - accuracy: 0.5157 - val_loss: 1.3208 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 8s 32ms/step - loss: 1.3008 - accuracy: 0.5163 - val_loss: 1.3229 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3220 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.3011 - accuracy: 0.5163 - val_loss: 1.3218 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3236 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 8s 32ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3271 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 8s 32ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3233 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 9s 35ms/step - loss: 1.2999 - accuracy: 0.5163 - val_loss: 1.3201 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 9s 35ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3224 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 8s 34ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3212 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.3212 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 8s 34ms/step - loss: 1.3163 - accuracy: 0.5129 - val_loss: 1.3225 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 10s 40ms/step - loss: 1.3001 - accuracy: 0.5163 - val_loss: 1.3227 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 8s 32ms/step - loss: 1.3016 - accuracy: 0.5163 - val_loss: 1.3213 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 8s 34ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3269 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 11s 44ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 8s 34ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3216 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 9s 37ms/step - loss: 1.2992 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 9s 36ms/step - loss: 1.3007 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 9s 35ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3235 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 9s 36ms/step - loss: 1.2996 - accuracy: 0.5163 - val_loss: 1.3206 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 1.3206 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3189 - accuracy: 0.5127 - val_loss: 1.3388 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3018 - accuracy: 0.5163 - val_loss: 1.3242 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3284 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3229 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3230 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3011 - accuracy: 0.5163 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3208 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 11s 44ms/step - loss: 1.2995 - accuracy: 0.5163 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.2996 - accuracy: 0.5163 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.2995 - accuracy: 0.5163 - val_loss: 1.3220 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.3220 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.3234 - accuracy: 0.5083 - val_loss: 1.3197 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3014 - accuracy: 0.5163 - val_loss: 1.3231 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 11s 42ms/step - loss: 1.3000 - accuracy: 0.5163 - val_loss: 1.3197 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3250 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3246 - val_accuracy: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3271 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3227 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3240 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 11s 44ms/step - loss: 1.2990 - accuracy: 0.5163 - val_loss: 1.3213 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.2995 - accuracy: 0.5163 - val_loss: 1.3205 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.3205 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 1.3427 - accuracy: 0.5115 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 17s 67ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3221 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 16s 64ms/step - loss: 1.3012 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3234 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3023 - accuracy: 0.5163 - val_loss: 1.3206 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3238 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3239 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3204 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3500 - accuracy: 0.5075 - val_loss: 1.3201 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3215 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3001 - accuracy: 0.5163 - val_loss: 1.3227 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3218 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.2996 - accuracy: 0.5163 - val_loss: 1.3237 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 15s 59ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3203 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3000 - accuracy: 0.5163 - val_loss: 1.3207 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.2999 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 1.2992 - accuracy: 0.5163 - val_loss: 1.3215 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3215 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.3190 - accuracy: 0.5123 - val_loss: 1.3220 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 1.3015 - accuracy: 0.5163 - val_loss: 1.3274 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 1.3010 - accuracy: 0.5163 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.3011 - accuracy: 0.5163 - val_loss: 1.3226 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.3010 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 1.3009 - accuracy: 0.5163 - val_loss: 1.3207 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3226 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3237 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3198 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3198 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 1.3213 - accuracy: 0.5093 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 1.3025 - accuracy: 0.5163 - val_loss: 1.3201 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 1.3022 - accuracy: 0.5163 - val_loss: 1.3199 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3227 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 12s 50ms/step - loss: 1.3027 - accuracy: 0.5163 - val_loss: 1.3265 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 1.3016 - accuracy: 0.5163 - val_loss: 1.3229 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 12s 48ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3207 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 13s 52ms/step - loss: 1.2995 - accuracy: 0.5163 - val_loss: 1.3236 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 13s 51ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3194 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3235 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 1.3235 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 16s 66ms/step - loss: 1.3247 - accuracy: 0.5104 - val_loss: 1.3224 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3216 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 1.3018 - accuracy: 0.5163 - val_loss: 1.3252 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 1.3012 - accuracy: 0.5163 - val_loss: 1.3201 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 1.3011 - accuracy: 0.5163 - val_loss: 1.3222 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 16s 64ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3228 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3239 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 16s 63ms/step - loss: 1.2993 - accuracy: 0.5163 - val_loss: 1.3234 - val_accuracy: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3213 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 1.3213 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.4204 - accuracy: 0.5132 - val_loss: 1.3367 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 1.3018 - accuracy: 0.5163 - val_loss: 1.3197 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.3018 - accuracy: 0.5163 - val_loss: 1.3226 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 1.3010 - accuracy: 0.5163 - val_loss: 1.3230 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3268 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 15s 61ms/step - loss: 1.3008 - accuracy: 0.5163 - val_loss: 1.3193 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3213 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3197 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.2990 - accuracy: 0.5163 - val_loss: 1.3400 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 15s 60ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3211 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.3211 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 87ms/step - loss: 1.5511 - accuracy: 0.5104 - val_loss: 1.3237 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 23s 91ms/step - loss: 1.3022 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3016 - accuracy: 0.5163 - val_loss: 1.3234 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3011 - accuracy: 0.5163 - val_loss: 1.3206 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.2995 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3216 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3206 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3009 - accuracy: 0.5163 - val_loss: 1.3215 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.2989 - accuracy: 0.5163 - val_loss: 1.3260 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.3260 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3553 - accuracy: 0.5139 - val_loss: 1.3302 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3018 - accuracy: 0.5163 - val_loss: 1.3227 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 22s 89ms/step - loss: 1.3019 - accuracy: 0.5163 - val_loss: 1.3213 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3017 - accuracy: 0.5163 - val_loss: 1.3212 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3201 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3007 - accuracy: 0.5163 - val_loss: 1.3202 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 21s 84ms/step - loss: 1.2995 - accuracy: 0.5163 - val_loss: 1.3225 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 21s 84ms/step - loss: 1.3001 - accuracy: 0.5163 - val_loss: 1.3240 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3213 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2993 - accuracy: 0.5163 - val_loss: 1.3218 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 1.3218 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.4608 - accuracy: 0.5094 - val_loss: 1.3269 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3010 - accuracy: 0.5163 - val_loss: 1.3224 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3013 - accuracy: 0.5163 - val_loss: 1.3220 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 21s 87ms/step - loss: 1.3007 - accuracy: 0.5163 - val_loss: 1.3264 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3008 - accuracy: 0.5163 - val_loss: 1.3241 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.2996 - accuracy: 0.5163 - val_loss: 1.3261 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3231 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.2988 - accuracy: 0.5163 - val_loss: 1.3259 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 22s 90ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3242 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3242 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 87ms/step - loss: 1.3500 - accuracy: 0.5129 - val_loss: 1.3246 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3029 - accuracy: 0.5163 - val_loss: 1.3212 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3026 - accuracy: 0.5163 - val_loss: 1.3218 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 22s 87ms/step - loss: 1.3016 - accuracy: 0.5163 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 22s 87ms/step - loss: 1.3015 - accuracy: 0.5163 - val_loss: 1.3216 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 22s 88ms/step - loss: 1.3009 - accuracy: 0.5163 - val_loss: 1.3246 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 21s 85ms/step - loss: 1.3000 - accuracy: 0.5163 - val_loss: 1.3264 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 21s 87ms/step - loss: 1.2993 - accuracy: 0.5163 - val_loss: 1.3203 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.2995 - accuracy: 0.5163 - val_loss: 1.3211 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 22s 88ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3253 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3253 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 32s 127ms/step - loss: 1.5500 - accuracy: 0.5108 - val_loss: 1.3244 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 32s 129ms/step - loss: 1.3030 - accuracy: 0.5163 - val_loss: 1.3226 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3000 - accuracy: 0.5163 - val_loss: 1.3215 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3202 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3284 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 32s 128ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3258 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 31s 127ms/step - loss: 1.3003 - accuracy: 0.5163 - val_loss: 1.3243 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3010 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.2990 - accuracy: 0.5163 - val_loss: 1.3220 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 32s 127ms/step - loss: 1.2999 - accuracy: 0.5163 - val_loss: 1.3241 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 2s 30ms/step - loss: 1.3241 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 4.2206 - accuracy: 0.5081 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 32s 130ms/step - loss: 1.3016 - accuracy: 0.5163 - val_loss: 1.3290 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 32s 129ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3244 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3009 - accuracy: 0.5163 - val_loss: 1.3234 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3241 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 32s 127ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3218 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3001 - accuracy: 0.5163 - val_loss: 1.3223 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.2997 - accuracy: 0.5163 - val_loss: 1.3214 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3208 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 2s 30ms/step - loss: 1.3208 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 45s 181ms/step - loss: 3.1150 - accuracy: 0.5062 - val_loss: 1.3299 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 45s 181ms/step - loss: 1.3008 - accuracy: 0.5163 - val_loss: 1.3224 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 44s 179ms/step - loss: 1.3008 - accuracy: 0.5163 - val_loss: 1.3227 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 45s 181ms/step - loss: 1.3005 - accuracy: 0.5163 - val_loss: 1.3214 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 45s 181ms/step - loss: 1.3000 - accuracy: 0.5163 - val_loss: 1.3222 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 45s 181ms/step - loss: 1.3002 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 44s 178ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3206 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 46s 185ms/step - loss: 1.2999 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 45s 181ms/step - loss: 1.3004 - accuracy: 0.5163 - val_loss: 1.3214 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 46s 185ms/step - loss: 1.2998 - accuracy: 0.5163 - val_loss: 1.3211 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1.3211 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 45s 183ms/step - loss: 2.5495 - accuracy: 0.5054 - val_loss: 1.3297 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 45s 182ms/step - loss: 1.3018 - accuracy: 0.5163 - val_loss: 1.3206 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 45s 183ms/step - loss: 1.3007 - accuracy: 0.5163 - val_loss: 1.3296 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 44s 178ms/step - loss: 1.3007 - accuracy: 0.5163 - val_loss: 1.3268 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 44s 176ms/step - loss: 1.3009 - accuracy: 0.5163 - val_loss: 1.3199 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 44s 176ms/step - loss: 1.3010 - accuracy: 0.5163 - val_loss: 1.3200 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 44s 177ms/step - loss: 1.3006 - accuracy: 0.5163 - val_loss: 1.3200 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 44s 177ms/step - loss: 1.2996 - accuracy: 0.5163 - val_loss: 1.3242 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 44s 177ms/step - loss: 1.2994 - accuracy: 0.5163 - val_loss: 1.3212 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 44s 177ms/step - loss: 1.2993 - accuracy: 0.5163 - val_loss: 1.3277 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 1.3277 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 8s 30ms/step - loss: 39.9772 - accuracy: 0.5081 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 7s 28ms/step - loss: 1.3073 - accuracy: 0.5163 - val_loss: 1.3246 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3077 - accuracy: 0.5163 - val_loss: 1.3212 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3105 - accuracy: 0.5163 - val_loss: 1.3346 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3078 - accuracy: 0.5163 - val_loss: 1.3266 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 8s 31ms/step - loss: 1.3098 - accuracy: 0.5163 - val_loss: 1.3372 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3062 - accuracy: 0.5163 - val_loss: 1.3254 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 1.3077 - accuracy: 0.5163 - val_loss: 1.3396 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3085 - accuracy: 0.5163 - val_loss: 1.3331 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3124 - accuracy: 0.5122 - val_loss: 1.3299 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.3299 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 16.0565 - accuracy: 0.5032 - val_loss: 1.3208 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 1.3029 - accuracy: 0.5163 - val_loss: 1.3263 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3057 - accuracy: 0.5163 - val_loss: 1.3281 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3225 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 1.3041 - accuracy: 0.5163 - val_loss: 1.3240 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3063 - accuracy: 0.5163 - val_loss: 1.3243 - val_accuracy: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3053 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 7s 29ms/step - loss: 1.3032 - accuracy: 0.5163 - val_loss: 1.3228 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3043 - accuracy: 0.5163 - val_loss: 1.3279 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 7s 30ms/step - loss: 1.3071 - accuracy: 0.5163 - val_loss: 1.3316 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 1.3316 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 82.3984 - accuracy: 0.5035 - val_loss: 1.3429 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 1.3082 - accuracy: 0.5163 - val_loss: 1.3199 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.3051 - accuracy: 0.5163 - val_loss: 1.3324 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 1.3091 - accuracy: 0.5163 - val_loss: 1.3340 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.3064 - accuracy: 0.5163 - val_loss: 1.3290 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 1.3060 - accuracy: 0.5163 - val_loss: 1.3303 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.3041 - accuracy: 0.5163 - val_loss: 1.3394 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.3074 - accuracy: 0.5163 - val_loss: 1.3299 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.3101 - accuracy: 0.5163 - val_loss: 1.3343 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 1.3034 - accuracy: 0.5163 - val_loss: 1.3224 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 1.3224 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 99.4056 - accuracy: 0.5100 - val_loss: 1.3256 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3194 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.3042 - accuracy: 0.5163 - val_loss: 1.3196 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 1.3053 - accuracy: 0.5163 - val_loss: 1.3292 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 11s 43ms/step - loss: 1.3045 - accuracy: 0.5163 - val_loss: 1.3235 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 1.3038 - accuracy: 0.5163 - val_loss: 1.3351 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3336 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 11s 44ms/step - loss: 1.3050 - accuracy: 0.5163 - val_loss: 1.3478 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 10s 41ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3256 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 10s 42ms/step - loss: 1.3089 - accuracy: 0.5163 - val_loss: 1.3375 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3375 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 41.8996 - accuracy: 0.5089 - val_loss: 1.3259 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.3045 - accuracy: 0.5163 - val_loss: 1.3245 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.3049 - accuracy: 0.5163 - val_loss: 1.3304 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 1.3055 - accuracy: 0.5163 - val_loss: 1.3257 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3054 - accuracy: 0.5163 - val_loss: 1.3253 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 13s 53ms/step - loss: 1.3033 - accuracy: 0.5163 - val_loss: 1.3293 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3297 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.3050 - accuracy: 0.5163 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.3042 - accuracy: 0.5163 - val_loss: 1.3273 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3068 - accuracy: 0.5163 - val_loss: 1.3298 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3298 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 202.0198 - accuracy: 0.5078 - val_loss: 1.3675 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.3064 - accuracy: 0.5163 - val_loss: 1.3228 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.3047 - accuracy: 0.5163 - val_loss: 1.3296 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.3075 - accuracy: 0.5163 - val_loss: 1.3296 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.3051 - accuracy: 0.5163 - val_loss: 1.3362 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3260 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.3064 - accuracy: 0.5163 - val_loss: 1.3315 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.3051 - accuracy: 0.5163 - val_loss: 1.3259 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3269 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 13s 54ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3241 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3241 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 12s 49ms/step - loss: 77.2215 - accuracy: 0.5089 - val_loss: 1.3212 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3046 - accuracy: 0.5163 - val_loss: 1.3274 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 12s 47ms/step - loss: 1.3066 - accuracy: 0.5163 - val_loss: 1.3242 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3037 - accuracy: 0.5163 - val_loss: 1.3341 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3057 - accuracy: 0.5163 - val_loss: 1.3278 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3059 - accuracy: 0.5163 - val_loss: 1.3235 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3050 - accuracy: 0.5163 - val_loss: 1.3224 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3052 - accuracy: 0.5163 - val_loss: 1.3247 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3048 - accuracy: 0.5163 - val_loss: 1.3228 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3039 - accuracy: 0.5163 - val_loss: 1.3240 - val_accuracy: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 8ms/step - loss: 1.3240 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 7.0322 - accuracy: 0.5056 - val_loss: 1.3233 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3046 - accuracy: 0.5163 - val_loss: 1.3308 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3050 - accuracy: 0.5163 - val_loss: 1.3291 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3059 - accuracy: 0.5163 - val_loss: 1.3243 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3060 - accuracy: 0.5163 - val_loss: 1.3302 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3026 - accuracy: 0.5163 - val_loss: 1.3344 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 11s 45ms/step - loss: 1.3047 - accuracy: 0.5163 - val_loss: 1.3254 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3048 - accuracy: 0.5163 - val_loss: 1.3205 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3033 - accuracy: 0.5163 - val_loss: 1.3306 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 11s 46ms/step - loss: 1.3058 - accuracy: 0.5163 - val_loss: 1.3308 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 1.3308 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 15s 62ms/step - loss: 352.7416 - accuracy: 0.5098 - val_loss: 1.3244 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 55ms/step - loss: 1.3050 - accuracy: 0.5163 - val_loss: 1.3224 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3080 - accuracy: 0.5163 - val_loss: 1.3213 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3035 - accuracy: 0.5163 - val_loss: 1.3245 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3053 - accuracy: 0.5163 - val_loss: 1.3243 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3058 - accuracy: 0.5163 - val_loss: 1.3232 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3028 - accuracy: 0.5163 - val_loss: 1.3282 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3046 - accuracy: 0.5163 - val_loss: 1.3392 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3064 - accuracy: 0.5163 - val_loss: 1.3256 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3053 - accuracy: 0.5163 - val_loss: 1.3298 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.3298 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1748.5184 - accuracy: 0.5065 - val_loss: 1.3239 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3025 - accuracy: 0.5163 - val_loss: 1.3312 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3032 - accuracy: 0.5163 - val_loss: 1.3309 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3053 - accuracy: 0.5163 - val_loss: 1.3262 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3046 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3061 - accuracy: 0.5163 - val_loss: 1.3249 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 14s 58ms/step - loss: 1.3050 - accuracy: 0.5163 - val_loss: 1.3383 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3061 - accuracy: 0.5163 - val_loss: 1.3217 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 14s 57ms/step - loss: 1.3046 - accuracy: 0.5163 - val_loss: 1.3254 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 14s 56ms/step - loss: 1.3038 - accuracy: 0.5163 - val_loss: 1.3292 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 1.3292 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1827.0280 - accuracy: 0.5074 - val_loss: 1.3306 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3262 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3060 - accuracy: 0.5163 - val_loss: 1.3321 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3051 - accuracy: 0.5163 - val_loss: 1.3232 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 84ms/step - loss: 1.3058 - accuracy: 0.5163 - val_loss: 1.3229 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3091 - accuracy: 0.5163 - val_loss: 1.3370 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 21s 84ms/step - loss: 1.3061 - accuracy: 0.5163 - val_loss: 1.3304 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3093 - accuracy: 0.5163 - val_loss: 1.3355 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3077 - accuracy: 0.5163 - val_loss: 1.3243 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3064 - accuracy: 0.5163 - val_loss: 1.3276 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3276 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 2877.7048 - accuracy: 0.5096 - val_loss: 1.3286 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 1.3045 - accuracy: 0.5163 - val_loss: 1.3281 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3044 - accuracy: 0.5163 - val_loss: 1.3231 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3051 - accuracy: 0.5163 - val_loss: 1.3413 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 20s 83ms/step - loss: 1.3051 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3030 - accuracy: 0.5163 - val_loss: 1.3254 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 1.3055 - accuracy: 0.5163 - val_loss: 1.3345 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 1.3079 - accuracy: 0.5163 - val_loss: 1.3248 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3039 - accuracy: 0.5163 - val_loss: 1.3366 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 1.3061 - accuracy: 0.5163 - val_loss: 1.3238 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 1.3238 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 3336.2197 - accuracy: 0.5032 - val_loss: 1.3204 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3074 - accuracy: 0.5163 - val_loss: 1.3299 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3059 - accuracy: 0.5163 - val_loss: 1.3208 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3071 - accuracy: 0.5163 - val_loss: 1.3281 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3063 - accuracy: 0.5163 - val_loss: 1.3244 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 20s 83ms/step - loss: 1.3056 - accuracy: 0.5163 - val_loss: 1.3239 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 20s 81ms/step - loss: 1.3063 - accuracy: 0.5163 - val_loss: 1.3374 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3069 - accuracy: 0.5163 - val_loss: 1.3326 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3121 - accuracy: 0.5163 - val_loss: 1.3526 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3076 - accuracy: 0.5163 - val_loss: 1.3286 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 1.3286 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 2301.8323 - accuracy: 0.4998 - val_loss: 1.3278 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3046 - accuracy: 0.5163 - val_loss: 1.3289 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3040 - accuracy: 0.5163 - val_loss: 1.3306 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 21s 86ms/step - loss: 1.3045 - accuracy: 0.5163 - val_loss: 1.3263 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 21s 84ms/step - loss: 1.3052 - accuracy: 0.5163 - val_loss: 1.3300 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 20s 82ms/step - loss: 1.3046 - accuracy: 0.5163 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3065 - accuracy: 0.5163 - val_loss: 1.3373 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3052 - accuracy: 0.5163 - val_loss: 1.3262 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3039 - accuracy: 0.5163 - val_loss: 1.3220 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 21s 83ms/step - loss: 1.3034 - accuracy: 0.5163 - val_loss: 1.3193 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3193 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 25246.0098 - accuracy: 0.4987 - val_loss: 1.3256 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3040 - accuracy: 0.5163 - val_loss: 1.3266 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3045 - accuracy: 0.5163 - val_loss: 1.3347 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 1.3029 - accuracy: 0.5163 - val_loss: 1.3201 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 30s 123ms/step - loss: 1.3033 - accuracy: 0.5163 - val_loss: 1.3244 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3048 - accuracy: 0.5163 - val_loss: 1.3266 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3041 - accuracy: 0.5163 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3030 - accuracy: 0.5163 - val_loss: 1.3227 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 1.3053 - accuracy: 0.5163 - val_loss: 1.3277 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 31s 126ms/step - loss: 1.3053 - accuracy: 0.5163 - val_loss: 1.3209 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 2s 28ms/step - loss: 1.3209 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 64620.7734 - accuracy: 0.5074 - val_loss: 1.3249 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3036 - accuracy: 0.5163 - val_loss: 1.3295 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 1.3059 - accuracy: 0.5163 - val_loss: 1.3354 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 31s 125ms/step - loss: 1.3052 - accuracy: 0.5163 - val_loss: 1.3310 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 32s 128ms/step - loss: 1.3054 - accuracy: 0.5163 - val_loss: 1.3245 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 31s 123ms/step - loss: 1.3040 - accuracy: 0.5163 - val_loss: 1.3257 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 1.3058 - accuracy: 0.5163 - val_loss: 1.3291 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 31s 123ms/step - loss: 1.3058 - accuracy: 0.5163 - val_loss: 1.3210 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 31s 123ms/step - loss: 1.3076 - accuracy: 0.5163 - val_loss: 1.3286 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 31s 124ms/step - loss: 1.3063 - accuracy: 0.5163 - val_loss: 1.3299 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 2s 29ms/step - loss: 1.3299 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 45s 180ms/step - loss: 52603.3359 - accuracy: 0.4953 - val_loss: 1.3310 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 44s 178ms/step - loss: 1.3047 - accuracy: 0.5163 - val_loss: 1.3234 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 44s 178ms/step - loss: 1.3135 - accuracy: 0.5163 - val_loss: 1.3349 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 45s 182ms/step - loss: 1.3107 - accuracy: 0.5138 - val_loss: 1.3398 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 44s 177ms/step - loss: 1.3088 - accuracy: 0.5163 - val_loss: 1.3309 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 44s 179ms/step - loss: 1.3084 - accuracy: 0.5163 - val_loss: 1.3293 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 45s 182ms/step - loss: 1.3134 - accuracy: 0.5163 - val_loss: 1.3465 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 45s 181ms/step - loss: 1.3118 - accuracy: 0.5163 - val_loss: 1.3219 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 44s 178ms/step - loss: 1.3083 - accuracy: 0.5163 - val_loss: 1.3336 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 45s 181ms/step - loss: 1.3088 - accuracy: 0.5163 - val_loss: 1.3271 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 1.3271 - accuracy: 0.5068\n",
      "Epoch 1/10\n",
      "248/248 [==============================] - 45s 180ms/step - loss: 173204.9375 - accuracy: 0.5023 - val_loss: 1.3451 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 44s 179ms/step - loss: 1.3113 - accuracy: 0.5163 - val_loss: 1.3357 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 44s 179ms/step - loss: 1.3066 - accuracy: 0.5163 - val_loss: 1.3308 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 44s 179ms/step - loss: 1.3057 - accuracy: 0.5163 - val_loss: 1.3252 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 44s 179ms/step - loss: 1.3068 - accuracy: 0.5163 - val_loss: 1.3424 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 44s 177ms/step - loss: 1.3080 - accuracy: 0.5163 - val_loss: 1.3236 - val_accuracy: 0.5068\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 45s 181ms/step - loss: 1.3069 - accuracy: 0.5163 - val_loss: 1.3237 - val_accuracy: 0.5068\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 44s 178ms/step - loss: 1.3068 - accuracy: 0.5163 - val_loss: 1.3226 - val_accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 44s 179ms/step - loss: 1.3085 - accuracy: 0.5163 - val_loss: 1.3364 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 44s 179ms/step - loss: 1.3082 - accuracy: 0.5163 - val_loss: 1.3437 - val_accuracy: 0.5068\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1.3437 - accuracy: 0.5068\n",
      "Best Hyperparameters:\n",
      "Learning Rate: 0.001\n",
      "Number of Filters: 16\n",
      "Filter Size: (5, 5)\n",
      "Number of Dense Layers: 2\n",
      "Best Accuracy: 0.5068078637123108\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "num_filters = [16, 32, 64]\n",
    "filter_sizes = [(3, 3), (5, 5), (7, 7)]\n",
    "num_dense_layers = [2, 3]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_hyperparams = None\n",
    "\n",
    "# Iterate over different hyperparameter combinations\n",
    "for lr in learning_rates:\n",
    "    for nf in num_filters:\n",
    "        for fs in filter_sizes:\n",
    "            for nd in num_dense_layers:\n",
    "                # Create the CNN model\n",
    "                model_cat = Sequential()\n",
    "\n",
    "                # Add convolutional layers\n",
    "                model_cat.add(Conv2D(nf, fs, activation='relu', input_shape=(64, 64, 3)))\n",
    "                model_cat.add(MaxPooling2D((2, 2)))\n",
    "                model_cat.add(Conv2D(nf, fs, activation='relu'))\n",
    "                model_cat.add(MaxPooling2D((2, 2)))\n",
    "                model_cat.add(Conv2D(nf, fs, activation='relu'))\n",
    "\n",
    "                # Flatten the output\n",
    "                model_cat.add(Flatten())\n",
    "\n",
    "                # Add dense layers\n",
    "                for _ in range(nd):\n",
    "                    model_cat.add(Dense(nf, activation='relu'))\n",
    "                model_cat.add(Dense(5, activation='softmax'))  #5 ranking categories\n",
    "\n",
    "                # Compile the model\n",
    "                optimizer = Adam(learning_rate=lr)\n",
    "                model_cat.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                # Train the model\n",
    "                model_cat.fit(x_train2, y_train2, epochs=10, validation_data=(x_test2, y_test2), verbose=1)\n",
    "\n",
    "                # Evaluate the model\n",
    "                _, accuracy = model_cat.evaluate(x_test2, y_test2, verbose=1)\n",
    "\n",
    "                # Check if current hyperparameters give a better recall\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_hyperparams = (lr, nf, fs, nd)\n",
    "\n",
    "# Print the best hyperparameters and corresponding accuracy\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(\"Learning Rate:\", best_hyperparams[0])\n",
    "print(\"Number of Filters:\", best_hyperparams[1])\n",
    "print(\"Filter Size:\", best_hyperparams[2])\n",
    "print(\"Number of Dense Layers:\", best_hyperparams[3])\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then use the hyperparameters that give us best accruacy to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "248/248 [==============================] - 17s 68ms/step - loss: 1.3205 - accuracy: 0.5115 - val_loss: 1.3256 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "248/248 [==============================] - 17s 69ms/step - loss: 1.3051 - accuracy: 0.5163 - val_loss: 1.3235 - val_accuracy: 0.5068\n",
      "Epoch 3/10\n",
      "248/248 [==============================] - 16s 66ms/step - loss: 1.3026 - accuracy: 0.5163 - val_loss: 1.3245 - val_accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "248/248 [==============================] - 17s 68ms/step - loss: 1.3008 - accuracy: 0.5163 - val_loss: 1.3245 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "248/248 [==============================] - 16s 66ms/step - loss: 1.2963 - accuracy: 0.5163 - val_loss: 1.3222 - val_accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "248/248 [==============================] - 16s 66ms/step - loss: 1.2887 - accuracy: 0.5165 - val_loss: 1.3266 - val_accuracy: 0.5053\n",
      "Epoch 7/10\n",
      "248/248 [==============================] - 19s 75ms/step - loss: 1.2761 - accuracy: 0.5163 - val_loss: 1.3360 - val_accuracy: 0.5038\n",
      "Epoch 8/10\n",
      "248/248 [==============================] - 17s 69ms/step - loss: 1.2446 - accuracy: 0.5195 - val_loss: 1.3661 - val_accuracy: 0.4947\n",
      "Epoch 9/10\n",
      "248/248 [==============================] - 17s 70ms/step - loss: 1.1909 - accuracy: 0.5315 - val_loss: 1.4601 - val_accuracy: 0.4685\n",
      "Epoch 10/10\n",
      "248/248 [==============================] - 17s 68ms/step - loss: 1.0786 - accuracy: 0.5718 - val_loss: 1.6103 - val_accuracy: 0.4463\n"
     ]
    }
   ],
   "source": [
    "# Create the CNN model\n",
    "model_cat = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model_cat.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model_cat.add(MaxPooling2D((2, 2)))\n",
    "model_cat.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_cat.add(MaxPooling2D((2, 2)))\n",
    "model_cat.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Flatten the output\n",
    "model_cat.add(Flatten())\n",
    "\n",
    "# Add dense layers\n",
    "model_cat.add(Dense(64, activation='relu'))\n",
    "model_cat.add(Dense(5, activation='softmax'))  #5 ranking categories\n",
    "\n",
    "# Compile the model\n",
    "model_cat.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_cat.fit(x_train2, y_train2, epochs=10, validation_data=(x_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_prob = model_cat.predict(x_test2)\n",
    "\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred2 = np.argmax(y_pred_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4462934947049924\n",
      "Precision: 0.22220726247480066\n",
      "Recall: 0.19625337396326112\n",
      "F1-score: 0.1694900132254871\n",
      "Confusion Matrix:\n",
      " [[  8 230  32   2   0]\n",
      " [ 29 835 124  13   4]\n",
      " [ 11 377  37   3   2]\n",
      " [  5 122  16   4   0]\n",
      " [  6 106  14   2   1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test2, y_pred2)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_test2, y_pred2, average='macro')\n",
    "recall = recall_score(y_test2, y_pred2, average='macro')\n",
    "f1 = f1_score(y_test2, y_pred2, average='macro')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test2, y_pred2)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1:\n",
      "Precision: 0.1356\n",
      "Recall: 0.0294\n",
      "F1-Score: 0.0483\n",
      "\n",
      "Category 2:\n",
      "Precision: 0.5000\n",
      "Recall: 0.8308\n",
      "F1-Score: 0.6243\n",
      "\n",
      "Category 3:\n",
      "Precision: 0.1659\n",
      "Recall: 0.0860\n",
      "F1-Score: 0.1133\n",
      "\n",
      "Category 4:\n",
      "Precision: 0.1667\n",
      "Recall: 0.0272\n",
      "F1-Score: 0.0468\n",
      "\n",
      "Category 5:\n",
      "Precision: 0.1429\n",
      "Recall: 0.0078\n",
      "F1-Score: 0.0147\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.03      0.05       272\n",
      "           1       0.50      0.83      0.62      1005\n",
      "           2       0.17      0.09      0.11       430\n",
      "           3       0.17      0.03      0.05       147\n",
      "           4       0.14      0.01      0.01       129\n",
      "\n",
      "    accuracy                           0.45      1983\n",
      "   macro avg       0.22      0.20      0.17      1983\n",
      "weighted avg       0.33      0.45      0.35      1983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, and F1-score for each category\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test2, y_pred2)\n",
    "\n",
    "# Print precision, recall, and F1-score for each category\n",
    "for category in range(1, 6):\n",
    "    print(f\"Category {category}:\")\n",
    "    print(f\"Precision: {precision[category-1]:.4f}\")\n",
    "    print(f\"Recall: {recall[category-1]:.4f}\")\n",
    "    print(f\"F1-Score: {f1_score[category-1]:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Generate a classification report\n",
    "classification_rep = classification_report(y_test2, y_pred2)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose my final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing accuracy, precision, recall, and f1-score, model 1 seems to perform better than the model_cat, so I will choose the first model to be my final cuteness ranking prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open('rater_model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save model weights\n",
    "model.save_weights('rater_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
